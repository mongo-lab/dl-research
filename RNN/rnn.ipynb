{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yqF-2Yvd1ER",
        "outputId": "c48f9272-769e-41ce-802c-9bac43c01c63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Epoch: 1 |train loss: 0.683 |cost: 3 m 4 s\n",
            "Epoch: 1 |evaluate loss: 0.69 |evaluate accuracy: 58.64\n",
            "Epoch: 2 |train loss: 0.691 |cost: 3 m 4 s\n",
            "Epoch: 2 |evaluate loss: 0.69 |evaluate accuracy: 52.52\n",
            "Epoch: 3 |train loss: 0.678 |cost: 3 m 5 s\n",
            "Epoch: 3 |evaluate loss: 0.69 |evaluate accuracy: 60.49\n",
            "Epoch: 4 |train loss: 0.636 |cost: 3 m 4 s\n",
            "Epoch: 4 |evaluate loss: 0.63 |evaluate accuracy: 64.80\n",
            "Epoch: 5 |train loss: 0.578 |cost: 3 m 3 s\n",
            "Epoch: 5 |evaluate loss: 0.49 |evaluate accuracy: 78.13\n",
            "Epoch: 6 |train loss: 0.419 |cost: 3 m 4 s\n",
            "Epoch: 6 |evaluate loss: 0.42 |evaluate accuracy: 82.45\n",
            "Epoch: 7 |train loss: 0.341 |cost: 3 m 5 s\n",
            "Epoch: 7 |evaluate loss: 0.38 |evaluate accuracy: 83.33\n",
            "Epoch: 8 |train loss: 0.307 |cost: 3 m 4 s\n",
            "Epoch: 8 |evaluate loss: 0.35 |evaluate accuracy: 85.12\n",
            "Epoch: 9 |train loss: 0.281 |cost: 3 m 5 s\n",
            "Epoch: 9 |evaluate loss: 0.34 |evaluate accuracy: 86.34\n",
            "Epoch: 10 |train loss: 0.250 |cost: 3 m 5 s\n",
            "Epoch: 10 |evaluate loss: 0.32 |evaluate accuracy: 87.26\n",
            "Epoch: 11 |train loss: 0.234 |cost: 3 m 4 s\n",
            "Epoch: 11 |evaluate loss: 0.30 |evaluate accuracy: 87.90\n",
            "Epoch: 12 |train loss: 0.220 |cost: 3 m 5 s\n",
            "Epoch: 12 |evaluate loss: 0.31 |evaluate accuracy: 87.57\n",
            "Epoch: 13 |train loss: 0.203 |cost: 3 m 4 s\n",
            "Epoch: 13 |evaluate loss: 0.32 |evaluate accuracy: 87.85\n",
            "Epoch: 14 |train loss: 0.182 |cost: 3 m 3 s\n",
            "Epoch: 14 |evaluate loss: 0.32 |evaluate accuracy: 88.08\n",
            "Epoch: 15 |train loss: 0.176 |cost: 3 m 4 s\n",
            "Epoch: 15 |evaluate loss: 0.32 |evaluate accuracy: 88.59\n",
            "Epoch: 16 |train loss: 0.164 |cost: 3 m 4 s\n",
            "Epoch: 16 |evaluate loss: 0.34 |evaluate accuracy: 88.15\n",
            "Epoch: 17 |train loss: 0.147 |cost: 3 m 4 s\n",
            "Epoch: 17 |evaluate loss: 0.32 |evaluate accuracy: 88.86\n",
            "Epoch: 18 |train loss: 0.146 |cost: 3 m 5 s\n",
            "Epoch: 18 |evaluate loss: 0.30 |evaluate accuracy: 89.04\n",
            "Epoch: 19 |train loss: 0.137 |cost: 3 m 5 s\n",
            "Epoch: 19 |evaluate loss: 0.37 |evaluate accuracy: 88.51\n",
            "Epoch: 20 |train loss: 0.121 |cost: 3 m 3 s\n",
            "Epoch: 20 |evaluate loss: 0.32 |evaluate accuracy: 88.59\n",
            "Epoch: 21 |train loss: 0.116 |cost: 3 m 4 s\n",
            "Epoch: 21 |evaluate loss: 0.37 |evaluate accuracy: 88.98\n",
            "Epoch: 22 |train loss: 0.111 |cost: 3 m 5 s\n",
            "Epoch: 22 |evaluate loss: 0.38 |evaluate accuracy: 89.05\n",
            "Epoch: 23 |train loss: 0.104 |cost: 3 m 5 s\n",
            "Epoch: 23 |evaluate loss: 0.35 |evaluate accuracy: 88.41\n",
            "Epoch: 24 |train loss: 0.099 |cost: 3 m 6 s\n",
            "Epoch: 24 |evaluate loss: 0.37 |evaluate accuracy: 88.99\n",
            "Epoch: 25 |train loss: 0.090 |cost: 3 m 4 s\n",
            "Epoch: 25 |evaluate loss: 0.37 |evaluate accuracy: 88.99\n",
            "Epoch: 26 |train loss: 0.086 |cost: 3 m 4 s\n",
            "Epoch: 26 |evaluate loss: 0.38 |evaluate accuracy: 89.02\n",
            "Epoch: 27 |train loss: 0.082 |cost: 3 m 3 s\n",
            "Epoch: 27 |evaluate loss: 0.40 |evaluate accuracy: 88.74\n",
            "Epoch: 28 |train loss: 0.081 |cost: 3 m 4 s\n",
            "Epoch: 28 |evaluate loss: 0.39 |evaluate accuracy: 88.90\n",
            "Epoch: 29 |train loss: 0.071 |cost: 3 m 6 s\n",
            "Epoch: 29 |evaluate loss: 0.41 |evaluate accuracy: 88.98\n",
            "Epoch: 30 |train loss: 0.067 |cost: 3 m 4 s\n",
            "Epoch: 30 |evaluate loss: 0.43 |evaluate accuracy: 88.05\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "# spacy 无法下载 解决办法 pip --default-timeout=10000 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.0/en_core_web_sm-2.3.0.tar.gz\n",
        "# 分词器\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "TEXT = data.Field(tokenize='spacy', tokenizer_language='en_core_web_sm')\n",
        "LABEL = data.LabelField(dtype=torch.float)\n",
        "\n",
        "# 切分数据集\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "\n",
        "# 构建词向量\n",
        "MAX_VOCAB_SIZE = 25_000\n",
        "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "# 整理数据集\n",
        "BATCH_SIZE = 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "train_iterator, test_iterator = data.BucketIterator.splits((train_data, test_data), batch_size=BATCH_SIZE,\n",
        "                                                           device=device)\n",
        "\n",
        "\n",
        "# 定义RNN\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, imput_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(imput_dim, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=2,\n",
        "                           bidirectional=True, dropout=0.5)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "\n",
        "        output, (hidden, cell) = self.rnn(embedding)\n",
        "        hidden = torch.cat([hidden[-2], hidden[-1]], dim=1)\n",
        "        hidden = self.dropout(hidden)\n",
        "        out = self.fc(hidden)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "# 定义维度\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "# model = nn.RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "model = model.to(device)\n",
        "\n",
        "# 计算二元交叉熵\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "# 优化器\n",
        "# optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), betas=(0.7, 0.995), lr=0.005)\n",
        "\n",
        "\n",
        "# 计算 accuracy\n",
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float()  # convert into float for division\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "\n",
        "\n",
        "# 训练方法\n",
        "def train(iterator):\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        # batch.text 就是上面forward函数的参数text，压缩维度是为了和batch.label维度一致\n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "# 测试方法\n",
        "def evaluate(iterator):\n",
        "    epoch_acc = 0\n",
        "    epoch_loss = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            epoch_acc += acc.item()\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_acc / len(iterator),epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "# 计算消耗时间\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "# 测试\n",
        "for epoch in range(30):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(train_iterator)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    torch.save(model.state_dict(), 'jn_rnn')\n",
        "\n",
        "    print(\n",
        "        'Epoch: %d |train loss: %.3f |cost: %d m %d s' % (\n",
        "            epoch + 1, train_loss, epoch_mins, epoch_secs))\n",
        "\n",
        "    test_acc,test_loss = evaluate(test_iterator)\n",
        "    print(\n",
        "        'Epoch: %d |evaluate loss: %.2f |evaluate accuracy: %.2f' % (epoch + 1, test_loss, test_acc * 100))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}