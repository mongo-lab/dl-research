{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zx7YEnH_IfsT",
    "outputId": "c23008fb-c3a8-4ab4-bc9d-04a4f22b773f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 |train loss: 1.559 |accuracy: 85 %\n",
      "Epoch: 1 |train loss: 0.487 |accuracy: 90 %\n",
      "Epoch: 1 |train loss: 0.329 |accuracy: 91 %\n",
      "Epoch: 2 |train loss: 0.261 |accuracy: 93 %\n",
      "Epoch: 2 |train loss: 0.228 |accuracy: 94 %\n",
      "Epoch: 2 |train loss: 0.203 |accuracy: 95 %\n",
      "Epoch: 3 |train loss: 0.182 |accuracy: 95 %\n",
      "Epoch: 3 |train loss: 0.155 |accuracy: 95 %\n",
      "Epoch: 3 |train loss: 0.146 |accuracy: 96 %\n",
      "Epoch: 4 |train loss: 0.138 |accuracy: 96 %\n",
      "Epoch: 4 |train loss: 0.124 |accuracy: 96 %\n",
      "Epoch: 4 |train loss: 0.114 |accuracy: 96 %\n",
      "Epoch: 5 |train loss: 0.111 |accuracy: 97 %\n",
      "Epoch: 5 |train loss: 0.102 |accuracy: 97 %\n",
      "Epoch: 5 |train loss: 0.104 |accuracy: 97 %\n",
      "Epoch: 6 |train loss: 0.093 |accuracy: 97 %\n",
      "Epoch: 6 |train loss: 0.094 |accuracy: 97 %\n",
      "Epoch: 6 |train loss: 0.086 |accuracy: 97 %\n",
      "Epoch: 7 |train loss: 0.077 |accuracy: 97 %\n",
      "Epoch: 7 |train loss: 0.081 |accuracy: 97 %\n",
      "Epoch: 7 |train loss: 0.086 |accuracy: 97 %\n",
      "Epoch: 8 |train loss: 0.080 |accuracy: 97 %\n",
      "Epoch: 8 |train loss: 0.072 |accuracy: 98 %\n",
      "Epoch: 8 |train loss: 0.073 |accuracy: 98 %\n",
      "Epoch: 9 |train loss: 0.067 |accuracy: 98 %\n",
      "Epoch: 9 |train loss: 0.070 |accuracy: 98 %\n",
      "Epoch: 9 |train loss: 0.068 |accuracy: 98 %\n",
      "Epoch: 10 |train loss: 0.067 |accuracy: 98 %\n",
      "Epoch: 10 |train loss: 0.067 |accuracy: 98 %\n",
      "Epoch: 10 |train loss: 0.058 |accuracy: 98 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1 prepare dataset\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# ToTensor  转换图片为张量\n",
    "# Normalized an tensor image with mean and standard deviation\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data/mnist/', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_dataset = datasets.MNIST(root='./data/mnist/', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# 2 design model\n",
    "\n",
    "model = nn.Sequential(\n",
    "    # 卷积1操作\n",
    "    # input: channel=1, out_channel=10, kernel_size5*5;\n",
    "    # output: h*w=(28-5+0+1)/1*(28-5+0+1)/1=24*24\n",
    "    nn.Conv2d(1, 10, kernel_size=5),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    # 卷积2操作 接收池化后的conv1 input(h*w)=h*w/2=24/2=12\n",
    "    # input: channel=10, out_channel=20, kernel_size5*5;\n",
    "    # output: h*w=(12-5+0+1)/1*(12-5+0+1)/1=8*8\n",
    "    nn.Conv2d(10, 20, kernel_size=5),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    # 全连接 接收池化后的conv2 input(h*w)=h*w/2=8/2=4\n",
    "    # input: 展开后为20*(4*4)=320\n",
    "    # output: 10 手写字10个分类\n",
    "    nn.Linear(320, 10))\n",
    "\n",
    "# 3 交叉熵损失函数 优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "# 4 training cycle forward, backward, update\n",
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for step, data in enumerate(train_loader, 0):\n",
    "        inputs, target = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if step % 300 == 299:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for l_data in test_loader:\n",
    "                    images, labels = l_data\n",
    "                    l_outputs = model(images)\n",
    "                    _, predicted = torch.max(l_outputs.data, dim=1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            print(\n",
    "                'Epoch: %d |train loss: %.3f |accuracy: %d %%' % (epoch + 1, running_loss / 300, 100 * correct / total))\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "def jn_cnn():\n",
    "    for epoch in range(10):\n",
    "        train(epoch)\n",
    "\n",
    "    torch.save(model, './jn_cnn')\n",
    "\n",
    "\n",
    "jn_cnn()\n",
    "\n",
    "# import torchvision.models as models\n",
    "# vgg16 = models.vgg16(pretrained=True)\n",
    "# vgg16.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NjTO059Ei8Ue",
    "outputId": "cfa723d0-b424-40ea-a43a-9053922d8fc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "JnVgg16(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch: 1 |step: 999 / 15000 |train loss: 0.972 |cost time: 41 s\n",
      "Epoch: 1 |step: 1999 / 15000 |train loss: 0.554 |cost time: 41 s\n",
      "Epoch: 1 |step: 2999 / 15000 |train loss: 0.452 |cost time: 40 s\n",
      "Epoch: 1 |step: 3999 / 15000 |train loss: 0.392 |cost time: 41 s\n",
      "Epoch: 1 |step: 4999 / 15000 |train loss: 0.368 |cost time: 40 s\n",
      "Epoch: 1 |step: 5999 / 15000 |train loss: 0.351 |cost time: 41 s\n",
      "Epoch: 1 |step: 6999 / 15000 |train loss: 0.331 |cost time: 40 s\n",
      "Epoch: 1 |step: 7999 / 15000 |train loss: 0.334 |cost time: 40 s\n",
      "Epoch: 1 |step: 8999 / 15000 |train loss: 0.310 |cost time: 40 s\n",
      "Epoch: 1 |step: 9999 / 15000 |train loss: 0.288 |cost time: 40 s\n",
      "Epoch: 1 |step: 10999 / 15000 |train loss: 0.289 |cost time: 40 s\n",
      "Epoch: 1 |step: 11999 / 15000 |train loss: 0.273 |cost time: 40 s\n",
      "Epoch: 1 |step: 12999 / 15000 |train loss: 0.254 |cost time: 40 s\n",
      "Epoch: 1 |step: 13999 / 15000 |train loss: 0.249 |cost time: 40 s\n",
      "Epoch: 1 |step: 14999 / 15000 |train loss: 0.249 |cost time: 40 s\n",
      "Epoch: 1 |accuracy: 89 % \n",
      "Epoch: 2 |step: 999 / 15000 |train loss: 0.232 |cost time: 40 s\n",
      "Epoch: 2 |step: 1999 / 15000 |train loss: 0.235 |cost time: 40 s\n",
      "Epoch: 2 |step: 2999 / 15000 |train loss: 0.214 |cost time: 40 s\n",
      "Epoch: 2 |step: 3999 / 15000 |train loss: 0.238 |cost time: 40 s\n",
      "Epoch: 2 |step: 4999 / 15000 |train loss: 0.238 |cost time: 40 s\n",
      "Epoch: 2 |step: 5999 / 15000 |train loss: 0.225 |cost time: 40 s\n",
      "Epoch: 2 |step: 6999 / 15000 |train loss: 0.220 |cost time: 40 s\n",
      "Epoch: 2 |step: 7999 / 15000 |train loss: 0.227 |cost time: 40 s\n",
      "Epoch: 2 |step: 8999 / 15000 |train loss: 0.223 |cost time: 40 s\n",
      "Epoch: 2 |step: 9999 / 15000 |train loss: 0.219 |cost time: 40 s\n",
      "Epoch: 2 |step: 10999 / 15000 |train loss: 0.238 |cost time: 40 s\n",
      "Epoch: 2 |step: 11999 / 15000 |train loss: 0.207 |cost time: 40 s\n",
      "Epoch: 2 |step: 12999 / 15000 |train loss: 0.207 |cost time: 40 s\n",
      "Epoch: 2 |step: 13999 / 15000 |train loss: 0.219 |cost time: 40 s\n",
      "Epoch: 2 |step: 14999 / 15000 |train loss: 0.194 |cost time: 40 s\n",
      "Epoch: 2 |accuracy: 92 % \n",
      "Epoch: 3 |step: 999 / 15000 |train loss: 0.179 |cost time: 40 s\n",
      "Epoch: 3 |step: 1999 / 15000 |train loss: 0.163 |cost time: 40 s\n",
      "Epoch: 3 |step: 2999 / 15000 |train loss: 0.189 |cost time: 40 s\n",
      "Epoch: 3 |step: 3999 / 15000 |train loss: 0.165 |cost time: 40 s\n",
      "Epoch: 3 |step: 4999 / 15000 |train loss: 0.176 |cost time: 40 s\n",
      "Epoch: 3 |step: 5999 / 15000 |train loss: 0.167 |cost time: 40 s\n",
      "Epoch: 3 |step: 6999 / 15000 |train loss: 0.175 |cost time: 40 s\n",
      "Epoch: 3 |step: 7999 / 15000 |train loss: 0.180 |cost time: 40 s\n",
      "Epoch: 3 |step: 8999 / 15000 |train loss: 0.197 |cost time: 40 s\n",
      "Epoch: 3 |step: 9999 / 15000 |train loss: 0.173 |cost time: 40 s\n",
      "Epoch: 3 |step: 10999 / 15000 |train loss: 0.189 |cost time: 40 s\n",
      "Epoch: 3 |step: 11999 / 15000 |train loss: 0.187 |cost time: 40 s\n",
      "Epoch: 3 |step: 12999 / 15000 |train loss: 0.189 |cost time: 40 s\n",
      "Epoch: 3 |step: 13999 / 15000 |train loss: 0.179 |cost time: 40 s\n",
      "Epoch: 3 |step: 14999 / 15000 |train loss: 0.165 |cost time: 40 s\n",
      "Epoch: 3 |accuracy: 92 % \n",
      "Epoch: 4 |step: 999 / 15000 |train loss: 0.142 |cost time: 40 s\n",
      "Epoch: 4 |step: 1999 / 15000 |train loss: 0.145 |cost time: 40 s\n",
      "Epoch: 4 |step: 2999 / 15000 |train loss: 0.154 |cost time: 40 s\n",
      "Epoch: 4 |step: 3999 / 15000 |train loss: 0.165 |cost time: 40 s\n",
      "Epoch: 4 |step: 4999 / 15000 |train loss: 0.158 |cost time: 40 s\n",
      "Epoch: 4 |step: 5999 / 15000 |train loss: 0.143 |cost time: 40 s\n",
      "Epoch: 4 |step: 6999 / 15000 |train loss: 0.155 |cost time: 40 s\n",
      "Epoch: 4 |step: 7999 / 15000 |train loss: 0.141 |cost time: 40 s\n",
      "Epoch: 4 |step: 8999 / 15000 |train loss: 0.149 |cost time: 40 s\n",
      "Epoch: 4 |step: 9999 / 15000 |train loss: 0.140 |cost time: 40 s\n",
      "Epoch: 4 |step: 10999 / 15000 |train loss: 0.150 |cost time: 40 s\n",
      "Epoch: 4 |step: 11999 / 15000 |train loss: 0.155 |cost time: 40 s\n",
      "Epoch: 4 |step: 12999 / 15000 |train loss: 0.153 |cost time: 40 s\n",
      "Epoch: 4 |step: 13999 / 15000 |train loss: 0.160 |cost time: 40 s\n",
      "Epoch: 4 |step: 14999 / 15000 |train loss: 0.141 |cost time: 40 s\n",
      "Epoch: 4 |accuracy: 93 % \n",
      "Epoch: 5 |step: 999 / 15000 |train loss: 0.112 |cost time: 40 s\n",
      "Epoch: 5 |step: 1999 / 15000 |train loss: 0.118 |cost time: 40 s\n",
      "Epoch: 5 |step: 2999 / 15000 |train loss: 0.128 |cost time: 40 s\n",
      "Epoch: 5 |step: 3999 / 15000 |train loss: 0.121 |cost time: 40 s\n",
      "Epoch: 5 |step: 4999 / 15000 |train loss: 0.128 |cost time: 40 s\n",
      "Epoch: 5 |step: 5999 / 15000 |train loss: 0.124 |cost time: 40 s\n",
      "Epoch: 5 |step: 6999 / 15000 |train loss: 0.136 |cost time: 40 s\n",
      "Epoch: 5 |step: 7999 / 15000 |train loss: 0.146 |cost time: 40 s\n",
      "Epoch: 5 |step: 8999 / 15000 |train loss: 0.124 |cost time: 40 s\n",
      "Epoch: 5 |step: 9999 / 15000 |train loss: 0.123 |cost time: 40 s\n",
      "Epoch: 5 |step: 10999 / 15000 |train loss: 0.114 |cost time: 40 s\n",
      "Epoch: 5 |step: 11999 / 15000 |train loss: 0.139 |cost time: 40 s\n",
      "Epoch: 5 |step: 12999 / 15000 |train loss: 0.127 |cost time: 40 s\n",
      "Epoch: 5 |step: 13999 / 15000 |train loss: 0.135 |cost time: 40 s\n",
      "Epoch: 5 |step: 14999 / 15000 |train loss: 0.118 |cost time: 40 s\n",
      "Epoch: 5 |accuracy: 93 % \n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import datetime\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: \", device)\n",
    "#\n",
    "batchSize = 4\n",
    "\n",
    "##load data\n",
    "transform = transforms.Compose([transforms.Resize(224), transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data/fashion/', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchSize, shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data/fashion/', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batchSize, shuffle=False, num_workers=0)\n",
    "\n",
    "# 导入预训练模型\n",
    "vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "# 打印vgg16结构\n",
    "print(vgg16)\n",
    "\n",
    "\n",
    "class JnVgg16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JnVgg16, self).__init__()\n",
    "\n",
    "        # 预训练vgg16的特征提取层\n",
    "        self.features = vgg16.features\n",
    "        self.features[0] = nn.Conv2d(1, 64, 3, 1, 1)\n",
    "\n",
    "        self.avgpool = vgg16.avgpool\n",
    "        # 添加新的全连接层\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(25088, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),  # 防止过拟合\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1024, 10)\n",
    "        )\n",
    "\n",
    "    # 定义前向传播路径\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        # x = x.view(-1, 25088)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 输出网络结构\n",
    "\n",
    "\n",
    "jn_vgg = JnVgg16()\n",
    "jn_vgg.to(device)\n",
    "# net = vgg16\n",
    "print(jn_vgg)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(jn_vgg.parameters(), lr=0.05, momentum=0.9)\n",
    "optimizer = optim.SGD(jn_vgg.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# train\n",
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    start = datetime.datetime.now()\n",
    "    total_step = len(trainloader)\n",
    "    for step, data in enumerate(trainloader, 0):\n",
    "        inputs, target = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if 'cpu' != device.type:\n",
    "            inputs = inputs.cuda()\n",
    "            target = target.cuda()\n",
    "        outputs = jn_vgg(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if step % 1000 == 999:\n",
    "            end = datetime.datetime.now()\n",
    "\n",
    "            interval = end - start\n",
    "\n",
    "            print('Epoch: %d |step: %d / %d |train loss: %.3f |cost time: %d s' % (epoch + 1, step, total_step, running_loss / 1000, interval.seconds))\n",
    "            running_loss = 0.0\n",
    "            start = datetime.datetime.now()\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model = jn_vgg\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for l_data in testloader:\n",
    "            images, labels = l_data\n",
    "            if 'cpu' != device.type:\n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "            l_outputs = model(images)\n",
    "            _, predicted = torch.max(l_outputs.data, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print('Epoch: %d |accuracy: %d %% ' % (epoch + 1, 100 * correct / total))\n",
    "\n",
    "\n",
    "def jn_vgg16_run():\n",
    "    for epoch in range(5):\n",
    "        train(epoch)\n",
    "        test(epoch)\n",
    "\n",
    "\n",
    "    # torch.save(jn_vgg, './model/jn_vgg16')\n",
    "\n",
    "\n",
    "jn_vgg16_run()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
